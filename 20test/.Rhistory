x <- matrix(rnorm(40), 5,8)
apply(x, 1, mean)
x
apply(x, 1, quantile, probs = c(0.1, 0.9))
help(quantile)
x <- 1:10
quantile(x, probs = c(0.25, 0.53))
a <- array(rnorm(20), c(1,2,3))
a
help(array)
install.packages("UsingR")
data(mtcars)
data(mtcars)
head(mtcars)
lm(mtcars$mpg~mtcars$cyl+mtcars$wt)
-1.508 *4
fit2 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2
fit <- lm(mtcars$mpg~mtcars$cyl+mtcars$wt)
fit
factor(cyl)8  = -6.071
# factor(cyl)8  = -6.071
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl), data = mtcars)
fit2$coefficients[3]
fit1
fit2
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
compare
fit2
fit3 <- lm(mpg ~ cyl + wt + interaction(cyl, wt), data = mtcars)
fit3
fit3$Pr
fit3
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
hatvalues(fit)
dfbetas(fit)
x <- c(0.18, -1.54, 0.42, 0.95)
##And weights given by
w <- c(2, 1, 3, 1)
mew <- c(1.077, 0.300, 0.0025, 0.1471)
for (each in mew){
total <- 0
#print(each)
#print(x[i])
#print(w[i])
for (i in 1:4){
total = total + w[i]*(x[i]-each)**2
}
print(total)
}
w(x-mew)**2
w*mean(x)
for (each in mew){
total <- 0
#print(each)
#print(x[i])
#print(w[i])
for (i in 1:4){
total = total + w[i]*(x[i]-each)**2
}
print(total)
}
w*(x-mew)*2
w*(x-mew)**2
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl), data = mtcars)
fit1
fit2
fit2$coefficients[3]
fit <- lm(y~x)
dfbetas(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
###Give the slope dfbeta for the point with the highest hat value.
fit <- lm(y~x)
dfbetas(fit)
w*(x-mew)**2
x <- c(0.18, -1.54, 0.42, 0.95)
##And weights given by
w <- c(2, 1, 3, 1)
###Give the value of μ that minimizes the least squares equation ∑ni=1wi(xi−μ)2
mew <- c(1.077, 0.300, 0.0025, 0.1471)
for (each in mew){
total <- 0
#print(each)
#print(x[i])
#print(w[i])
for (i in 1:4){
total = total + w[i]*(x[i]-each)**2
}
print(total)
}
w*(x-mew)**2
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
lm(y~x-1)
lm(y~x-1.567)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x-1.567)
lm(y~I(x-1.567)
)
lm(y ~ x-1)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl), data = mtcars)
fit1
fit2
fit2$coefficients[3]
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
##Fit the regression through the origin and get the slope treating y as the outcome and x as the regressor. (Hint, do not center the data since we want regression through the origin, not through the means of the data.)
lm(y~x)
lm(y ~ x-1)
data(mtcars)
head(mtcars)
lm(mpg~wt, data=mtcars)
#######quzi1
###Consider the data set given below
x <- c(0.18, -1.54, 0.42, 0.95)
##And weights given by
w <- c(2, 1, 3, 1)
###Give the value of μ that minimizes the least squares equation ∑ni=1wi(xi−μ)2
mew <- c(1.077, 0.300, 0.0025, 0.1471)
for (each in mew){
total <- 0
#print(each)
#print(x[i])
#print(w[i])
for (i in 1:4){
total = total + w[i]*(x[i]-each)**2
}
print(total)
}
w*(x-mew)**2
#######question2
##Consider the following data set
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
##Fit the regression through the origin and get the slope treating y as the outcome and x as the regressor. (Hint, do not center the data since we want regression through the origin, not through the means of the data.)
lm(y~x)
##Call:
##lm(formula = y ~ x)
###Coefficients:
##(Intercept)= 1.567
lm(y ~ x-1)
##Coefficients: x  = 0.8263
#####question3
###Do data(mtcars) from the datasets package and fit the regression model with mpg as the outcome and weight as the predictor. Give the slope coefficient.
data(mtcars)
head(mtcars)
lm(mpg~wt, data=mtcars)
#####question4
###Consider data with an outcome (Y) and a predictor (X). The standard deviation of the predictor is one half that of the outcome. The correlation between the two variables is .5. What value would the slope coefficient for the regression model with Y as the outcome and X as the predictor?
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
###What is the value of the first measurement if x were normalized (to have mean 0 and variance 1)?
xc <- (x-mean(x))/sd(x)
xc
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
# What value minimizes the sum of the squared distances
# between these points and itself?
xmean <- mean(x)
xmean
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
####Give a P-value for the two sided hypothesis test of whether β1 from a linear regression model is 0 or not.
fit <- lm(y ~ x)
fit1
fit
t.test(y, x, paired = False)
t.test(y, x, paired = FALSE)
t.test(y, x)
summary(fit)
data(mtcars)
lm(mpg ~ wt,data = mtcars)
fit2 <- lm(mpg ~ wt,data = mtcars)
summary(fit2)
newdata <- data.frame(wt=mean(wt))
newdata <- data.frame(wt=mean(mtcars$wt))
x <- predit(fit2, newdata, interval=("confidence"))
newdata <- data.frame(wt=mean(mtcars$wt))
x <- predict(fit2, newdata, interval=("confidence"))
x
help(mtcars)
data(mtcars)
fit2 <- lm(mpg ~ wt,data = mtcars)
summary(fit2)
data(mtcars)
fit2 <- lm(mpg ~ wt,data = mtcars)
summary(fit2)
newdata2 <- data.frame(wt = 3)
x <- predict(fit2, newdata2, interval = ("prediction"))
x
data(mtcars)
fit2 <- lm(mpg ~ wt,data = mtcars)
summary(fit2)
newdata3 <- data.frame(wt = 2)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 1)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 2)
x <- predict(fit2, newdata3, interval = ("prediction"))
newdata3 <- data.frame(wt = 2)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 2000)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 2)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 1/2)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 1/2000)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt = 2)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt=mean(2mtcars$wt))
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt=mean(2*mtcars$wt))
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt=mean(0.5*mtcars$wt))
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt=mean(0.5*mtcars$wt))
x <- predict(fit2, newdata3, interval = ("prediction"))
x
newdata3 <- data.frame(wt=2)
x <- predict(fit2, newdata3, interval = ("prediction"))
x
data(mtcars)
wt <- (1/2) * mtcars$wt
mpg <- mtcars$mpg
fit <- lm(mpg ~ wt)
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.95, df = fit$df) * sumCoef[2, 2]
t <- (1/2) * mtcars$wt
mpg <- mtcars$mpg
fit3 <- lm(mpg ~ wt)
sumCoef <- summary(fit3)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.95, df = fit3$df) * sumCoef[2, 2]
#####question7
sumCoef
sumCoef[2,1] + c(-1, 1) * qt(.95, df = fit3$df) * sumCoef[2, 2]
newdata4 <- data.frame(wt=mean(mtcars$wt))
x <- predict(fit3, newdata4, interval = ("prediction"))
x
sumCoef <- summary(fit3)$coefficients
sumCoef
sumCoef[2,1]
fit3$df
fit3
summary(fit3)
sumCoef[2, 2]
data(mtcars)
lm(y ~ offset(x))
fit <- lm(mpg ~ wt, mtcars)
anova(fit)
(847.73)/(847.73 + 278.32)
# another method = get Multiple R-squared from summary of lm ( didn't work)??
fit <- lm(mpg ~ wt, mtcars)
fit2 <- lm(mpg ~ offset(wt), mtcars)
a <- summary(fit）
a <- summary(fit)
a
anova(fit)
(847.73)/(847.73 + 278.32)
install.packages("lattice")
install.packages("ggplot2")
install.packages("caret")
install.packages("randomForest")
install.packages("corrplot")
install.packages("parallel")
install.packages("gbm")
install.packages("plyr")
install.packages("survival")
install.packages("splines")
set.seed(1234)
library(caret); library(kernlab); library(randomForest); library(corrplot)
data_training <- read.csv("pml-training.csv", na.strings= c("NA",""," "))
setwd("~/Documents/R/R Code /practice machine learning")
set.seed(1234)
library(caret); library(kernlab); library(randomForest); library(corrplot)
### read the csv file for training
data_training <- read.csv("pml-training.csv", na.strings= c("NA",""," "))
data_training <- read.csv("pml-training.csv", na.strings= c("NA",""," "))
data_training_NA <- apply(data_training, 2, function(x){
sum(is.na(x))
})
data_training_new1 <- data_training[, which(data_training_NA == 0)]
data_training_new2 <- data_training_new1[8:length(data_training_new1)]
inTrain <- createDataPartition(y = data_training_new2$classe, p = 0.7, list = FALSE)
training <- data_training_new2[inTrain, ]
crossval <- data_training_new2[-inTrain, ]
cor <- abs(sapply(colnames(training[, -ncol(training)]), function(x) cor(as.numeric(training[, x]), as.numeric(training$classe), method = "spearman")))
summary(cor)
plot(training[, names(which.max(cor))], training[, names(which.max(cor[-which.max(cor)]))], col = training$classe, pch = 19, cex = 0.1, xlab = names(which.max(cor)), ylab = names(which.max(cor[-which.max(cor)])))
dev.off()
plot(training[, names(which.max(cor))], training[, names(which.max(cor[-which.max(cor)]))], col = training$classe, pch = 19, cex = 0.1, xlab = names(which.max(cor)), ylab = names(which.max(cor[-which.max(cor)])))
cor <- abs(sapply(colnames(training[, -ncol(training)]), function(x) cor(as.numeric(training[, x]), as.numeric(training$classe), method = "spearman")))
summary(cor)
png("plot1.png", width = 480, height = 480)
plot(training[, names(which.max(cor))], training[, names(which.max(cor[-which.max(cor)]))], col = training$classe, pch = 19, cex = 0.1, xlab = names(which.max(cor)), ylab = names(which.max(cor[-which.max(cor)])))
dev.off()
correlMatrix <- cor(training[, -length(training)])
correlMatrix
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
boostFit <- train(classe ~ ., method = "gbm", data = training, verbose = FALSE)
boostFit <- train(classe ~ ., method = "gbm", data = training, verbose = FALSE)
print(boostFit)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
plot(boostFit, ylim = c(0.9, 1))
boostFit <- train(classe ~ ., method = "gbm", data = training, verbose = FALSE)
print(boostFit)
png("plot3.png", width = 480, height = 480)
plot(boostFit, ylim = c(0.9, 1))
dev.off()
RandomForestFit<- randomForest(classe ~ ., data = training)
RandomForestFit
png("boostFit.png", width = 480, height = 480)
plot(boostFit, ylim = c(0.9, 1))
dev.off()
png("corrplot.png", width = 480, height = 480)
corrplot(correlMatrix, order = "FPC", method = "circle", type = "lower", tl.cex = 0.8,  tl.col = rgb(0, 0, 0))
dev.off()
rfFit <- train(classe ~ ., method = "rf", data = training, importance = T)
rfFit
plot(RandomForestFit, ylim = c(0.9, 1))
plot(rfFit, ylim = c(0.9, 1))
png("rfFit.png", width = 480, height = 480)
plot(rfFit, ylim = c(0.9, 1))
dev.off()
help(varImp)
imp <- varImp(rfFit)
imp
imp$importance
imp$max <- apply(imp, 1, max)
imp$max
imp$max <- apply(imp, 1, max)
imp$max <- sapply(imp, 1, max)
imp <- varImp(rfFit)
imp$importance
imp$max <- apply(imp, 1, fun(x){
max(x)
})
imp$max <- apply(imp, 1, fun(x){
max(x)
})
imp$max
imp
impMax <- apply(imp, 1, max)
impMax <- apply(imp$importance, 1, max)
impMax
imp <- varImp(rfFit)$importance
imp$Max <- apply(imp, 1, max)
impNew <- imp[order(imp$max, decreasing = T)]
impNew <- imp[order(imp$max, decreasing = T), ]
imp
impNew <- imp[order(imp$Max, decreasing = T), ]
impNew
predictCrossVal <- predict(rfFit, crossval)
confusionMatrix(crossval$classe, predictCrossVal)
data_testing <- read.csv("pml-testing.csv", na.strings= c("NA",""," "))
data_testing_NA <- apply(data_testing, 2, function(x){sum(is.na(x))})
data_testing_new1 <- data_testing[, which(data_testing_NA == 0)]
testing <- data_testing_new1[8:length(data_testing_new1)]
View(testing)
predictTest <- predict(rfFit, testing)
predictTest
cor <- abs(sapply(colnames(training[, -ncol(training)]), function(x) cor(as.numeric(training[, x]), as.numeric(training$classe), method = "spearman")))
summary(cor)
plot(training[, names(which.max(cor))], training[, names(which.max(cor[-which.max(cor)]))], col = training$classe, pch = 19, cex = 0.1, xlab = names(which.max(cor)), ylab = names(which.max(cor[-which.max(cor)])))
boostFit$Accuracy
rfFit
prediction <- predict(rfFit, testing)
prediction
confusionMatrix(predictions, testing$classe)
confusionMatrix(prediction, testing$classe)
boostFit
help(train)
bstFit <- train(classe ~ ., method = "gbm", data = training)
bstFit
l
help(markdown)
??markdown
```{r, eval=FALSE}
setwd("~/Documents/R/R Code /practice machine learning/20test")
answers = rep("A", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers = rep(" ", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write
answers = rep(" ", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
data(?shuttle)
library(MASS)
data(?shuttle)
data(shuttle)
head(shuttle)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), lable = c(1,0))
fit1 <- glm(use ~ wind -1, data = shuttle, family = "binomial")
summary(fit)
windhead <- fit1$coef[1]
windtial <- fit1$coef[2]
exp(windtail)/exp(windhead)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), lable = c(1,0))
fit1 <- glm(use ~ wind -1, data = shuttle, family = "binomial")
summary(fit1)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), lables = c(1,0))
fit1 <- glm(use ~ wind -1, data = shuttle, family = "binomial")
summary(fit1)
windhead <- fit1$coef[1]
windtail <- fit1$coef[2]
exp(windtail)/exp(windhead)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit1 <- glm(use ~ wind -1, data = shuttle, family = "binomial")
summary(fit1)
windhead <- fit1$coef[1]
windtail <- fit1$coef[2]
exp(windtail)/exp(windhead)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
summary(fit2)
windhead2 <- fit2$coef[1]
windtail2 <- fit2$coef[2]
exp(windtail2)/exp(windhead2)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
summary(fit2)
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
head(shuttle)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit1 <- glm(use ~ wind -1, data = shuttle, family = "binomial")
summary(fit1)
windhead <- fit1$coef[1]
windtail <- fit1$coef[2]
exp(windtail)/exp(windhead)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
summary(fit)
fit2 <- glm(use ~ wind + magn, data = shuttle, family = "binomial")
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
summary(fit)
windhead2 <- fit2$coef[1]
windtail2 <- fit2$coef[2]
exp(windtail2)/exp(windhead2)
help(shutle)
help(shuttle)
View(shuttle)
View(shuttle)
shuttle$auto <- as.numeric(shuttle$use=="auto")
fit <- glm(auto ~ wind,  binomial,  shuttle)
fit3 <- glm(1-auto ~ wind,  binomial, shuttle)
fit$coefficients
fit3$coefficients
help(glm)
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
shuttle$use
View(shuttle)
View(shuttle)
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
shuttle$auto <- as.numeric(shuttle$use=="auto")
fit <- glm(auto ~ wind,  binomial,  data = shuttle)
